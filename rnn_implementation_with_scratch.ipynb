{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0148c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244feca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation functions\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return 1 - np.tanh(x) ** 2\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))\n",
    "    return exp_x / np.sum(exp_x)\n",
    "\n",
    "def cross_entropy(pred, label):\n",
    "    return -np.log(pred[label, 0] + 1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b2e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RNN layers\n",
    "class SimpleRNN:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Weights\n",
    "        self.Wxh = np.random.randn(hidden_size, input_size) * 0.01\n",
    "        self.Whh = np.random.randn(hidden_size, hidden_size) * 0.01\n",
    "        self.Why = np.random.randn(output_size, hidden_size) * 0.01\n",
    "\n",
    "        self.bh = np.zeros((hidden_size, 1))\n",
    "        self.by = np.zeros((output_size, 1))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        self.h = {}\n",
    "        self.h[-1] = np.zeros((self.hidden_size, 1))\n",
    "\n",
    "        # Forward through time\n",
    "        for t in range(len(inputs)):\n",
    "            x = inputs[t].reshape(-1, 1)\n",
    "            self.h[t] = tanh(\n",
    "                np.dot(self.Wxh, x) +\n",
    "                np.dot(self.Whh, self.h[t - 1]) +\n",
    "                self.bh\n",
    "            )\n",
    "\n",
    "        # Output\n",
    "        y = np.dot(self.Why, self.h[len(inputs) - 1]) + self.by\n",
    "        return softmax(y)\n",
    "\n",
    "    def backward(self, d_y, lr=0.01):\n",
    "        dWhy = np.dot(d_y, self.h[len(self.inputs) - 1].T)\n",
    "        dby = d_y\n",
    "\n",
    "        dWxh = np.zeros_like(self.Wxh)\n",
    "        dWhh = np.zeros_like(self.Whh)\n",
    "        dbh = np.zeros_like(self.bh)\n",
    "\n",
    "        dh_next = np.zeros_like(self.h[0])\n",
    "\n",
    "        # Backpropagation Through Time (BPTT)\n",
    "        for t in reversed(range(len(self.inputs))):\n",
    "            dh = np.dot(self.Why.T, d_y) + dh_next\n",
    "            dtanh = dh * tanh_derivative(self.h[t])\n",
    "\n",
    "            dbh += dtanh\n",
    "            dWxh += np.dot(dtanh, self.inputs[t].reshape(1, -1))\n",
    "            dWhh += np.dot(dtanh, self.h[t - 1].T)\n",
    "            dh_next = np.dot(self.Whh.T, dtanh)\n",
    "\n",
    "        # Gradient Descent Update\n",
    "        self.Wxh -= lr * dWxh\n",
    "        self.Whh -= lr * dWhh\n",
    "        self.Why -= lr * dWhy\n",
    "        self.bh -= lr * dbh\n",
    "        self.by -= lr * dby\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72cab44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "def train(model, X, Y, epochs=10, lr=0.01):\n",
    "    for epoch in range(epochs):\n",
    "        loss = 0\n",
    "        for x, y in zip(X, Y):\n",
    "            pred = model.forward(x)\n",
    "            loss += cross_entropy(pred, y)\n",
    "\n",
    "            grad = pred\n",
    "            grad[y] -= 1\n",
    "            model.backward(grad.reshape(-1, 1), lr)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} | Loss: {loss/len(X):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7efde517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 0.6953\n",
      "Epoch 2 | Loss: 0.6944\n",
      "Epoch 3 | Loss: 0.6938\n",
      "Epoch 4 | Loss: 0.6932\n",
      "Epoch 5 | Loss: 0.6927\n",
      "Epoch 6 | Loss: 0.6923\n",
      "Epoch 7 | Loss: 0.6920\n",
      "Epoch 8 | Loss: 0.6918\n",
      "Epoch 9 | Loss: 0.6916\n",
      "Epoch 10 | Loss: 0.6914\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "np.random.seed(0)\n",
    "\n",
    "# 20 samples\n",
    "# Each sample = sequence of length 5\n",
    "# Each timestep has 3 features\n",
    "X = [np.random.rand(5, 3) for _ in range(20)]\n",
    "Y = np.random.randint(0, 2, 20)  # Binary classification\n",
    "\n",
    "rnn = SimpleRNN(input_size=3, hidden_size=16, output_size=2)\n",
    "train(rnn, X, Y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
